# CRM System Web Crawling 데이터 수집 자동화

## 1. 프로젝트 개요

- 프로젝트명: CRM Web Crawling 데이터 수집 자동화
- 프로젝트 소속: 고영테크놀러지
- 프로젝트 기간: 2024.08
- 프로젝트 인원: 1명

### 프로젝트 개요
본 프로젝트는 CRM(Customer Relationship Management) 시스템 내 장비 및 고객 이력 데이터를  
자동으로 수집하여 딥러닝 학습 데이터로 활용하기 위한 데이터 수집 자동화 프로젝트이다.

CRM 시스템은 웹 기반 UI로만 제공되며,  
보안 및 운영 정책상 DB 직접 접근이나 공식 API가 제공되지 않는 구조였다.

또한 운영 서버의 파일 시스템에 직접 접근하는 방식은  
권한 관리 및 서비스 안정성 측면에서 현실적이지 않았기 때문에  
기존 웹 UI 접근 흐름을 자동화하는 웹 크롤링 기반 방식을 선택하였다.

### 시스템 아키텍처
본 시스템은 Selenium 기반 웹 UI 자동화를 통해 CRM 목록 페이지에서 장비별 상세 페이지 **링크를 수집**하고,  
수집된 링크를 기반으로 상세 페이지에 접근하여 웹 스크래핑을 통해 파일 메타데이터를 확인한 뒤  
조건에 맞는 파일만 선택적으로 다운로드하는 구조로 설계되었다.

<img src="images/new_archi.png" alt="CRM Crawling Architecture" width="600"/>

### 프로젝트 목표
- 웹 UI 기반 CRM 시스템에서 장비 및 고객 이력 데이터 자동 수집
- 동적 로딩 구조에서도 안정적으로 동작하는 크롤링 시스템 구축
- 대용량 데이터 수집 시 서버 및 클라이언트 리소스 낭비 최소화
- 딥러닝 학습용 데이터셋 확보를 위한 데이터 정제

---

## 2. 담당 역할

### 웹 크롤링 자동화 설계
- CRM 시스템 HTML / DOM 구조 분석
- Selenium 기반 크롤링 아키텍처 설계

### 동적 페이지 대응
- 무한 스크롤(Infinite Scroll) 방식 페이지 대응
- JavaScript 기반 동적 데이터 로딩 처리

### 데이터 수집 로직 구현
- 장비 이력 목록 자동 스크롤 수집
- 상세 페이지 링크 추출 및 CSV 파일 저장
- CSV 기반 링크 재접근 구조 설계

### 성능 최적화 및 안정성 확보
- 데이터 파일 크기 사전 확인 로직 구현
- 대용량 파일 다운로드 제한 정책 적용
- 크롤링 예외 처리 및 안정성 강화

---

## 3. 기술적 문제 및 해결

### 문제 1. 동적 로딩 페이지 및 페이지 초기화 문제

CRM 시스템은 스크롤을 내릴 때마다 데이터가 동적으로 로드되며,  
개별 데이터 링크 접근 후 뒤로 이동할 경우 페이지 상태가 초기화되는 구조였다.

이로 인해 데이터 누락 및 반복 스크롤로 인한 성능 저하 문제가 발생하였다.

#### 해결 방법
- 자동 스크롤 기능을 구현하여 페이지 내 모든 데이터를 한 번에 로딩
- 로딩 완료 후 모든 상세 페이지 링크를 CSV 파일로 저장
- CSV 파일을 기반으로 링크를 하나씩 접근하도록 구조 변경

이를 통해 동적 로딩 문제와 페이지 초기화 문제를 동시에 해결하였다.

---

### 문제 2. 대용량 데이터로 인한 리소스 낭비

수집 대상 데이터의 파일 크기가 최소 수 MB부터 최대 10GB 이상까지 다양하였다.  
파일 크기 확인 없이 일괄 다운로드 시 디스크 용량 및 네트워크 리소스 낭비 가능성이 존재하였다.

#### 해결 방법
- HTTP 요청 헤더를 통해 파일 크기 정보를 사전 조회
- 사전에 정의한 임계값을 초과하는 파일은 다운로드 대상에서 제외
- 필요 데이터만 선택적으로 수집하도록 로직 개선

이를 통해 서버 및 클라이언트 리소스를 효율적으로 제어하였다.

## 3-1. Web Crawling Automation Flow

CRM 웹 UI의 실제 사용자 동작 흐름을 기반으로 다음 단계를 자동화하였다.

1. 대상 데이터 Element 탐색 (DOM 분석)
2. 동적 로딩 페이지 대응을 위한 자동 스크롤 처리
3. 상세 페이지 접근 및 파일 다운로드 자동화

![CRM Crawling Flow](images/flow.png)

---

## 4. 결과 및 성과

- 동적 로딩 페이지에 대응 가능한 웹 크롤링 자동화 시스템 구축
- 수작업 대비 약 80% 이상의 데이터 수집 시간 단축
- 10MB ~ 10GB 규모의 장비 이력 데이터 약 1만건 안정적 수집
- 딥러닝 모델 개발에 필요한 CRM 데이터셋 확보
- 데이터 수집 자동화를 통한 후속 AI 프로젝트 생산성 향상

---

## 5. 사용 기술

- Language
  - Python

- Web Crawling / Automation
  - Selenium
  - requests

- Web / Network
  - HTML / DOM 구조 분석
  - HTTP 통신 구조 이해

- Data Processing
  - CSV 처리

---

## 6. 프로젝트 의의

본 프로젝트는 단순한 웹 크롤링 구현을 넘어 API나 DB 접근이 불가능한 제한된 환경에서도  
실무에 적용 가능한 안정적인 데이터 수집 자동화 시스템을 구축한 사례이다.

동적 로딩 UI 대응, 대용량 데이터 처리 전략, 성능 최적화를 종합적으로 고려하여  
딥러닝 프로젝트의 데이터 파이프라인 기반을 마련하였다.

이를 통해 수작업 기반 데이터 수집 프로세스를 자동화하여  
데이터 확보 시간을 단축하고, 이후 딥러닝 모델 개발에 집중할 수 있는  
환경을 구축하였다.
